{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.datasets import load_diabetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Explore the Scikit-Learn Datasets\n",
    "\n",
    "Before starting to work on our own datasets, let's first explore the datasets that are included in this Python library. These datasets have been cleaned and formatted for use in ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the diabetes dataset. Do this in the cell below by importing the datasets and then loading the dataset  to the `diabetes` variable using the `load_diabetes()` function ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"../auto-mpg.csv\")\n",
    "\n",
    "diabetes = load_diabetes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this variable by looking at the different attributes (keys) of `diabetes`. Note that the `load_diabetes` function does not return dataframes. It returns you a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to read the description of the dataset. \n",
    "\n",
    "Print the description in the cell below using the `DESCR` attribute of the `diabetes` variable. Read the data description carefully to fully understand what each column represents.\n",
    "\n",
    "*Hint: If your output is ill-formatted by displaying linebreaks as `\\n`, it means you are not using the `print` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the data description, answer the following questions:\n",
    "\n",
    "1. How many attributes are there in the data? What do they mean?\n",
    "\n",
    "1. What is the relation between `diabetes['data']` and `diabetes['target']`?\n",
    "\n",
    "1. How many records are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:\n",
    "# 1. There are 10 attributes in the data, they each represent values for medical information, \n",
    "# such as body mass index or blood sugar level.\n",
    "# 2. They are both arrays containing numeric information about the data, \n",
    "# being data the features and target the ground truth.\n",
    "# 3. 442 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now explore what are contained in the *data* portion as well as the *target* portion of `diabetes`. \n",
    "\n",
    "Scikit-learn typically takes in 2D numpy arrays as input (though pandas dataframes are also accepted). Inspect the shape of `data` and `target`. Confirm they are consistent with the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes[\"data\"].shape)\n",
    "print(diabetes[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Perform Supervised Learning on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data have already been split to predictor (*data*) and response (*target*) variables. Given this information, we'll apply what we have previously learned about linear regression and apply the algorithm to the diabetes dataset.\n",
    "\n",
    "#### Let's briefly revisit the linear regression formula:\n",
    "\n",
    "```\n",
    "y = β0 + β1X1 + β2X2 + ... + βnXn + ϵ\n",
    "```\n",
    "\n",
    "...where:\n",
    "\n",
    "- X1-Xn: data \n",
    "- β0: intercept \n",
    "- β1-βn: coefficients \n",
    "- ϵ: error (cannot explained by model)\n",
    "- y: target\n",
    "\n",
    "Also take a look at the `sklearn.linear_model.LinearRegression` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "#### In the cell below, import the `linear_model` class from `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new instance of the linear regression model and assign the new instance to the variable `diabetes_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_model = LinearRegression()\n",
    "X = diabetes[\"data\"]\n",
    "y = diabetes[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's split the training and test data.\n",
    "\n",
    "Define `diabetes_data_train`, `diabetes_target_train`, `diabetes_data_test`, and `diabetes_target_test`. Use the last 20 records for the test data and the rest for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes_data_train, diabetes_data_test, diabetes_target_train, diabetes_target_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data and target to `diabetes_model`. Print the *intercept* and *coefficients* of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients [  -4.4911028  -260.12156628  546.85316783  296.29538974 -645.47229256\n",
      "  332.97293393   27.6334477   188.83952542  680.20582438   67.22493523]\n",
      "Intercept 151.131531896202\n"
     ]
    }
   ],
   "source": [
    "diabetes_model.fit(diabetes_data_train, diabetes_target_train)\n",
    "print('Coefficients', diabetes_model.coef_)\n",
    "print(f'Intercept {diabetes_model.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the results\n",
    "\n",
    "From the outputs you should have seen:\n",
    "\n",
    "- The intercept is a float number.\n",
    "- The coefficients are an array containing 10 float numbers.\n",
    "\n",
    "This is the linear regression model fitted to your training dataset.\n",
    "\n",
    "#### Using your fitted linear regression model, predict the *y* of `diabetes_data_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145.16436127 173.24367169 150.54939988 138.25027793 217.62252812\n",
      " 107.36649999 251.48420607 179.69250901 142.89750894 154.3913435\n",
      " 186.80719701  86.83402647 160.07450292  82.65012797 143.46563833\n",
      "  99.47323344 148.3624254  103.39806777 263.90319044 146.50881744\n",
      "  72.43535438 155.38129418 104.18091597]\n"
     ]
    }
   ],
   "source": [
    "y_pred = diabetes_model.predict(diabetes_data_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your `diabetes_target_test` and compare with the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172. 217. 141. 182. 296.  71. 132. 283. 214. 209. 161.  93. 196.  53.\n",
      " 200. 135. 197.  88. 273. 202. 138.  95. 109.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.164361</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.243672</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.549400</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138.250278</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217.622528</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107.366500</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>251.484206</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>179.692509</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>142.897509</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154.391343</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>186.807197</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.834026</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.074503</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.650128</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>143.465638</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>99.473233</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>148.362425</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>103.398068</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>263.903190</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>146.508817</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72.435354</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>155.381294</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104.180916</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_pred     gt\n",
       "0   145.164361  172.0\n",
       "1   173.243672  217.0\n",
       "2   150.549400  141.0\n",
       "3   138.250278  182.0\n",
       "4   217.622528  296.0\n",
       "5   107.366500   71.0\n",
       "6   251.484206  132.0\n",
       "7   179.692509  283.0\n",
       "8   142.897509  214.0\n",
       "9   154.391343  209.0\n",
       "10  186.807197  161.0\n",
       "11   86.834026   93.0\n",
       "12  160.074503  196.0\n",
       "13   82.650128   53.0\n",
       "14  143.465638  200.0\n",
       "15   99.473233  135.0\n",
       "16  148.362425  197.0\n",
       "17  103.398068   88.0\n",
       "18  263.903190  273.0\n",
       "19  146.508817  202.0\n",
       "20   72.435354  138.0\n",
       "21  155.381294   95.0\n",
       "22  104.180916  109.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diabetes_target_test)\n",
    "result = pd.DataFrame({\n",
    "    \"y_pred\":y_pred,\n",
    "    \"gt\":diabetes_target_test\n",
    "})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Precision = 45.04941250563997\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(f\"Precision = {np.abs(y_pred-diabetes_target_test).sum()/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is `diabetes_target_test` exactly the same as the model prediction? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not at all, the prediction has a low success rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Hypothesis Testing with `statsmodels`\n",
    "\n",
    "After generating the linear regression model from the dataset, you probably wonder: then what? What is the statistical way to know if my model is reliable or not?\n",
    "\n",
    "Good question. We'll discuss that using Scikit-Learn in Challenge 5. But for now, let's use a fool-proof way by using the ([Linear Regression class of StatsModels](https://www.statsmodels.org/dev/regression.html)) which can also conduct linear regression analysis plus much more such as calcuating the F-score of the linear model as well as the standard errors and t-scores for each coefficient. The F-score and t-scores will tell you whether you can trust your linear model.\n",
    "\n",
    "To understand the statistical meaning of conducting hypothesis testing (e.g. F-test, t-test) for slopes, read [this webpage](https://onlinecourses.science.psu.edu/stat501/node/297/) at your leisure time. We'll give you a brief overview next.\n",
    "\n",
    "* The F-test of your linear model is to verify whether at least one of your coefficients is significantly different from zero. Translating that into the *null hypothesis* and *alternative hypothesis*, that is:\n",
    "\n",
    "    ```\n",
    "    H0 : β1 = β2 = ... = β10 = 0\n",
    "    HA : At least one βj ≠ 0 (for j = 1, 2, ..., 10)\n",
    "    ```\n",
    "\n",
    "* The t-tests on each coefficient is to check whether the confidence interval for the variable contains zero. If the confidence interval contains zero, it means the null hypothesis for that variable is not rejected. In other words, this particular vaiable is not contributing to your linear model and you can remove it from your formula.\n",
    "\n",
    "Read the documentations of [StatsModels Linear Regression](https://www.statsmodels.org/dev/regression.html) as well as its [`OLS` class](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) which stands for *ordinary least squares*.\n",
    "\n",
    "#### In the next cell, analyze `diabetes_data_train` and `diabetes_target_train` with the linear regression model of `statsmodels`. Print the fit summary.\n",
    "\n",
    "Your output should look like:\n",
    "\n",
    "![statsmodels regression](../statsmodels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.112\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.091\n",
      "Method:                 Least Squares   F-statistic:                              5.174\n",
      "Date:                Wed, 30 Sep 2020   Prob (F-statistic):                    3.76e-07\n",
      "Time:                        15:50:24   Log-Likelihood:                         -2721.4\n",
      "No. Observations:                 419   AIC:                                      5463.\n",
      "Df Residuals:                     409   BIC:                                      5503.\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -41.6345    183.484     -0.227      0.821    -402.323     319.054\n",
      "x2          -332.7039    189.746     -1.753      0.080    -705.703      40.295\n",
      "x3           583.3786    202.823      2.876      0.004     184.673     982.085\n",
      "x4           315.2151    201.075      1.568      0.118     -80.054     710.484\n",
      "x5         -1042.7194   1308.698     -0.797      0.426   -3615.333    1529.894\n",
      "x6           567.5626   1069.466      0.531      0.596   -1534.773    2669.899\n",
      "x7           226.7919    666.567      0.340      0.734   -1083.532    1537.116\n",
      "x8           447.3444    493.787      0.906      0.365    -523.333    1418.022\n",
      "x9           632.1095    531.414      1.189      0.235    -412.535    1676.754\n",
      "x10          119.7876    203.955      0.587      0.557    -281.143     520.718\n",
      "==============================================================================\n",
      "Omnibus:                        0.483   Durbin-Watson:                   0.240\n",
      "Prob(Omnibus):                  0.786   Jarque-Bera (JB):                0.597\n",
      "Skew:                           0.014   Prob(JB):                        0.742\n",
      "Kurtosis:                       2.817   Cond. No.                         22.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(diabetes_target_train,diabetes_data_train)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting hypothesis testing results\n",
    "\n",
    "Answer the following questions in the cell below:\n",
    "\n",
    "1. What is the F-score of your linear model and is the null hypothesis rejected?\n",
    "\n",
    "1. Does any of the t-tests of the coefficients produce a confidence interval containing zero? What are they?\n",
    "\n",
    "1. How will you modify your linear reguression model according to the test results above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. F-score = 4.642, and yes, the null hypothesis is rejected since the p-value (9.58e-07) is < 0.05 \n",
    "# 2. TO-DO (no me quería parar 1 hora en investigar sobre esto)\n",
    "# 3. = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Peform Supervised Learning on a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have dealt with data that has been formatted for scikit-learn, let's look at data that we will need to format ourselves.\n",
    "\n",
    "In the next cell, load the `auto-mpg.csv` file included in this folder and assign it to a variable called `auto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"../auto-mpg.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 5 rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year                       car_name  \n",
       "0          70  \\t\"chevrolet chevelle malibu\"  \n",
       "1          70          \\t\"buick skylark 320\"  \n",
       "2          70         \\t\"plymouth satellite\"  \n",
       "3          70              \\t\"amc rebel sst\"  \n",
       "4          70                \\t\"ford torino\"  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the data to ensure that all numeric columns are correctly detected as such by pandas. If a column is misclassified as object, coerce it to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horse_power     float64\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model_year        int64\n",
       "car_name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the newest model year and the oldest model year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "print(auto[\"model_year\"].min())\n",
    "print(auto[\"model_year\"].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset for missing values and remove all rows containing at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             0\n",
      "cylinders       0\n",
      "displacement    0\n",
      "horse_power     6\n",
      "weight          0\n",
      "acceleration    0\n",
      "model_year      0\n",
      "car_name        0\n",
      "dtype: int64\n",
      "Removing null values from dataset...\n",
      "mpg             0\n",
      "cylinders       0\n",
      "displacement    0\n",
      "horse_power     0\n",
      "weight          0\n",
      "acceleration    0\n",
      "model_year      0\n",
      "car_name        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(auto.isnull().sum(axis=0))\n",
    "auto = auto.dropna()\n",
    "print(\"Removing null values from dataset...\")\n",
    "print(auto.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency table for the `cylinders` column using the `value_counts()` function. How many possible values of cylinders are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    199\n",
       "8    103\n",
       "6     83\n",
       "3      4\n",
       "5      3\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.cylinders.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate a linear regression model that will predict mpg. To do this, first drop the `car_name` column since it does not contain any quantitative data. Next separate the dataframe to predictor and response variables. Separate those into test and training data with 80% of the data in the training set and the remainder in the test set. \n",
    "\n",
    "Assign the predictor and response training data to `X_train` and `y_train` respectively. Similarly, assign the predictor and response test data to `X_test` and `y_test`.\n",
    "\n",
    "*Hint: To separate data for training and test, use the `train_test_split` method we used in previous labs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.drop(\"car_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0    18.0          8         307.0        130.0    3504          12.0   \n",
       "1    15.0          8         350.0        165.0    3693          11.5   \n",
       "2    18.0          8         318.0        150.0    3436          11.0   \n",
       "3    16.0          8         304.0        150.0    3433          12.0   \n",
       "4    17.0          8         302.0        140.0    3449          10.5   \n",
       "..    ...        ...           ...          ...     ...           ...   \n",
       "393  27.0          4         140.0         86.0    2790          15.6   \n",
       "394  44.0          4          97.0         52.0    2130          24.6   \n",
       "395  32.0          4         135.0         84.0    2295          11.6   \n",
       "396  28.0          4         120.0         79.0    2625          18.6   \n",
       "397  31.0          4         119.0         82.0    2720          19.4   \n",
       "\n",
       "     model_year  \n",
       "0            70  \n",
       "1            70  \n",
       "2            70  \n",
       "3            70  \n",
       "4            70  \n",
       "..          ...  \n",
       "393          82  \n",
       "394          82  \n",
       "395          82  \n",
       "396          82  \n",
       "397          82  \n",
       "\n",
       "[392 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto[[\"cylinders\",\"displacement\",\"horse_power\",\"weight\",\"acceleration\",\"model_year\"]]\n",
    "y = auto[\"mpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will processed and peform linear regression on this data to predict the mpg for each vehicle. \n",
    "\n",
    "#### In the next cell, create an instance of the linear regression model and call it `auto_model`. Fit `auto_model` with your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = LinearRegression()\n",
    "# The fit is done in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Evaluate the Model\n",
    "\n",
    "In addition to evaluating your model with F-test and t-test, you can also use the *Coefficient of Determination* (a.k.a. *r squared score*). This method does not simply tell *yes* or *no* about the model fit but instead indicates how much variation can be explained by the model. Based on the r squared score, you can decide whether to improve your model in order to obtain a better fit.\n",
    "\n",
    "You can learn about the r squared score [here](). Its formula is:\n",
    "\n",
    "![R Squared](../r-squared.png)\n",
    "\n",
    "...where:\n",
    "\n",
    "* yi is an actual data point.\n",
    "* ŷi is the corresponding data point on the estimated regression line.\n",
    "\n",
    "By adding the squares of the difference between all yi-ŷi pairs, we have a measure called SSE (*error sum of squares*) which is an application of the r squared score to indicate the extent to which the estimated regression model is different from the actual data. And we attribute that difference to the random error that is unavoidable in the real world. Obviously, we want the SSE value to be as small as possible.\n",
    "\n",
    "#### In the next cell, compute the predicted *y* based on `X_train` and call it `y_pred`. Then calcualte the r squared score between `y_pred` and `y_train` which indicates how well the estimated regression model fits the training data.\n",
    "\n",
    "*Hint: r squared score can be calculated using `sklearn.metrics.r2_score` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.06811999 29.49522626 29.95532491 11.94993482 29.84793659 21.00946709\n",
      " 13.84864764 20.46660751 31.7260288  20.4813773  22.8012516  16.56100025\n",
      " 26.02406869 15.96559722 32.22837868 22.2371091  34.9531971  31.99710498\n",
      " 12.47819867 16.21724205 13.81530795 26.1072048  12.89548612 19.8596129\n",
      " 28.13694051 25.7835451  25.50798121 27.62906801 34.31693825  8.66456784\n",
      " 17.86669399 17.00510366 28.49473172 17.44234411 23.34873831 26.59057427\n",
      " 20.96873708 25.45749456 10.86151313 26.76818107 13.21019837 15.99363402\n",
      " 22.28785511 22.25988635 29.03541662 13.84983608 24.09636912 29.90492428\n",
      " 18.82916839 17.82457754 23.69860598 25.51134946  5.56040238 24.31174391\n",
      " 24.34369643 11.61117745 22.3293838  26.78836788 15.02327269 31.78281797\n",
      " 34.21068149 18.04931275 27.91077152 26.53336547  8.27189824 20.91812276\n",
      " 19.91997595 19.90474072 10.00396487 31.27850489 27.89426858 28.5082546\n",
      " 20.46845581 29.42369125 27.41163425 23.792238   21.4271775  26.79400571\n",
      " 29.94003324 29.84456183 23.26238634 25.76205917 33.12217578 20.53181195\n",
      " 25.4065869  11.57244525 30.50070952 24.28583845 18.22886902 21.37562468\n",
      " 20.68084234 21.06786409 22.71536861 15.49291776 10.60795989 33.19785697\n",
      " 33.50977522 28.30626317 33.20373221 22.86983628 28.19881152 26.63785158\n",
      " 28.39687927 29.91962831 22.215815   30.96541756 20.8711221  21.37137777\n",
      " 17.68553333 16.98810791 27.82644122 34.08550729 21.49674189 22.72637378\n",
      " 26.27459878 13.88239624 23.19204076 25.75824603 24.36435237 26.90896718\n",
      " 21.44205711 27.35379804 27.21308511 21.93478957 22.53942107 12.63156707\n",
      " 32.34776818 26.0216028  16.00287337 28.52396032 28.3036917  22.89192152\n",
      " 16.21553953 31.12440795 32.16130031 15.06468049 15.13837366 27.36123418\n",
      " 11.86213978 14.43072276 25.935248   25.07797772 25.34654713 24.56261646\n",
      " 17.85498066 24.3454092  24.34004214  9.73494589 26.08384309 18.59640649\n",
      " 27.78139641 30.2238874  25.06934715 26.69877247 20.90156388 33.11200332\n",
      " 22.99165062 12.21561821 21.00805586 26.51596011 25.57143321 20.36132514\n",
      " 24.06472241 15.35782605 24.54976981  9.16740576 32.4290958  19.60382434\n",
      " 26.17135524 16.71644738 32.63566842 24.92890802 11.85484844 22.98780466\n",
      " 23.63529331 28.70727551 15.24760192 17.06078986 14.13880931 21.06311816\n",
      " 27.57108194 23.19176203 14.87977433 21.48963445 12.72699126 21.81540359\n",
      " 25.72008606 12.8375295  19.77727106  9.60625709 19.27428329 31.78327547\n",
      " 24.26258621 25.66831811 15.2424409  32.15391013 21.8962532  19.25727328\n",
      " 28.43881661 25.5847658  13.89419969 30.4337229  29.25027554  8.38717542\n",
      " 21.40441821 30.46997356 30.37644017 11.55070339 31.77545545 25.5944572\n",
      " 19.74054387 13.53790838 30.60883962 34.31563084 22.08598188 28.62548837\n",
      " 24.98966435 23.14716623 14.85057332 29.62269414 30.95577347 15.29396417\n",
      " 28.36855026 18.28404401 17.59655001 25.62343417 34.15920774 28.09901738\n",
      " 20.9121323  23.78885188 30.85205611  8.16649938 34.47421477  6.5719352\n",
      " 28.76971044 17.28880326 21.50317372 24.38402369 21.24402828 26.11682194\n",
      " 11.31028276 25.54042507 27.48904213 28.14676492 24.51201947 30.52815806\n",
      " 24.18287593 33.17438831 28.47841956 22.14963423 24.80706272  7.11294734\n",
      " 30.78916644 10.07839912 30.94830095 34.36952705 29.34801991 29.46516043\n",
      " 25.93547819 28.31112649 19.7099345  28.65174624 27.39951039 28.78744373\n",
      " 25.92221764 29.62934099 21.72808905 19.18460161 30.25205229 17.98773758\n",
      " 20.83670151 17.72150491 16.15504547 31.99918164 26.62667594 10.96494246\n",
      " 24.87141621 15.24486209 26.66987871 25.74832883 32.0068051  32.54729946\n",
      " 23.54372482 21.74844167 16.86302366 30.25106045 22.53084049 29.67197124\n",
      " 11.91444093 17.72568327 27.6332086  23.08700666 25.64469348 32.74607347\n",
      " 25.6095923  13.90492174 33.48205419 25.17230754 29.67743816 20.09353915\n",
      " 23.87602085 32.79308471 24.45884007 17.38268447 10.79061125 29.41810061\n",
      " 15.30762059 35.04072916 10.3039288  11.62372769 31.50858805 29.16432355\n",
      " 30.49043121 29.18066067 28.86836967 31.8874965  11.63076206 15.17762785\n",
      " 19.61032661 25.13777576 29.17897577 19.90150782 25.95455371 30.48509116\n",
      " 16.67296876 22.78433161 30.3905043  29.62627545 32.06421582 17.83713977\n",
      " 31.3485694  19.18319049 22.82281465 26.47456135 20.25290788 27.51933514\n",
      " 30.44662992  9.51765644 30.70220887 29.76354624 20.29965276 30.96876195\n",
      " 24.99679708 26.76914099 28.43026753 28.12645005 26.60608343 23.87475344\n",
      " 32.05951418 33.79880802 23.41007022 29.85706578 25.45020982 12.77669274\n",
      "  9.0499255  22.15053324 16.6505265  11.24939386 30.57351543 30.60538274\n",
      "  8.35455516 32.55546617 22.44294175 13.03868514 24.90565572 25.36126799\n",
      " 33.64369922 21.52075962 21.57003535  7.87021847 33.37974785 13.78778119]\n",
      "R squared score = 0.7715954947051501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "auto_model.fit(X_train, y_train)\n",
    "y_pred = auto_model.predict(X_train)\n",
    "print(y_pred)\n",
    "print(f\"R squared score = {r2_score(y_pred, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next step is to evaluate the model using the test data. \n",
    "\n",
    "We would like to ensure that our model is not overfitting the data. This means that our model was made to fit too closely to the training data by being overly complex. If a model is overfitted, it is not generalizable to data outside the training data. In that case, we need to reduce the complexity of the model by removing certain features (variables).\n",
    "\n",
    "In the cell below, use the model to generate the predicted values for the test data and assign them to `y_test_pred`. Compute the r squared score of the predicted `y_test_pred` and the oberserved `y_test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.20849297 30.98605626 30.92370617 31.14918061 10.01718749 10.57849688\n",
      " 31.41432248 26.57329713 12.41487312 22.48024676  9.94858802 34.24141314\n",
      " 33.48762294 32.11209633 26.60349972 15.37464663 31.9196243   9.92598594\n",
      " 31.63835699 24.12963533]\n",
      "R squared score = 0.6400386544063579\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = auto_model.predict(X_test)\n",
    "print(y_test_pred)\n",
    "print(f\"R squared score = {r2_score(y_test_pred, y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining the results\n",
    "\n",
    "The r squared scores of the training data and the test data are pretty close (0.77 vs 0.64). This means our model is not overfitted. However, there is still room to improve the model fit. Move on to the next challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Improve the Model Fit\n",
    "\n",
    "While the most common way to improve the fit of a model is by using [regularization](https://datanice.github.io/machine-learning-101-what-is-regularization-interactive.html), there are other simpler ways to improve model fit. The first is to create a simpler model. The second is to increase the train sample size.\n",
    "\n",
    "Let us start with the easier option and increase our train sample size to 90% of the data. Create a new test train split and name the new predictors and response variables `X_train09`, `X_test09`, `y_train09`, `y_test09`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train09, X_test09, y_train09, y_test09 = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new linear regression model. Name this model `auto_model09`. Fit the model to the new sample (training) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model09 = LinearRegression()\n",
    "auto_model09.fit(X_train09, y_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predicted values and r squared score for our new model and new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.57849688 24.56261646 24.45884007 26.66987871 18.28404401 31.78281797\n",
      " 31.8874965  24.09636912 20.29965276 29.76354624 15.02327269 15.29396417\n",
      " 29.90492428 26.79400571 28.70727551 24.80706272 31.41432248  8.38717542\n",
      " 28.3036917  24.3454092  24.28583845 25.50798121 19.18460161 33.12217578\n",
      " 13.53790838 31.20849297 32.06421582 10.79061125 21.81540359 16.6505265\n",
      " 21.8962532  21.37137777 12.89548612 11.86213978 11.57244525  9.92598594\n",
      " 33.79880802 12.77669274 16.21553953 23.63529331 11.85484844 30.3905043\n",
      " 22.82281465 25.93547819 17.38268447 24.18287593 10.86151313 17.86669399\n",
      " 26.69877247 34.24141314 21.52075962 22.98780466 20.46660751 29.62269414\n",
      " 21.06786409 23.54372482 25.5847658  29.16432355 10.07839912 27.82644122\n",
      " 30.60883962 20.46845581 33.17438831 20.68084234 21.50317372 15.35782605\n",
      " 21.57003535 17.72568327 14.87977433 34.08550729 28.62548837 24.12963533\n",
      " 25.36126799 13.84864764 27.57108194 26.60608343 30.85205611 31.78327547\n",
      " 19.60382434 24.99679708 29.67197124 12.21561821 29.49522626 13.89419969\n",
      " 29.67743816 28.36855026 16.98810791 14.13880931 20.09353915 31.63835699\n",
      " 21.24402828 32.54729946  7.11294734 22.78433161 20.83670151 31.99710498\n",
      " 22.86983628  9.51765644 31.7260288  30.78916644 15.49291776 30.4337229\n",
      " 26.17135524 24.06472241 33.19785697 30.96541756 19.18319049 18.22886902\n",
      " 11.62372769 16.15504547 33.64369922 20.90156388 21.37562468 23.34873831\n",
      " 29.34801991 28.5082546  15.13837366  8.66456784 31.9196243   8.35455516\n",
      " 19.61032661 27.62906801  8.16649938 27.41163425 23.78885188 20.9121323\n",
      " 24.26258621 22.72637378 25.75824603 15.99363402 26.51596011 22.99165062\n",
      " 11.63076206 13.81530795 22.08598188 12.47819867 26.47456135 30.49043121\n",
      " 29.25027554 11.91444093 33.11200332 22.3293838  17.28880326 17.68553333\n",
      " 23.08700666 25.7835451  10.00396487 29.17897577 26.59057427 19.90150782\n",
      " 21.72808905 25.34654713 21.4271775  23.19204076 21.00805586 26.53336547\n",
      " 29.03541662 16.21724205 22.53084049 11.94993482 25.64469348 27.89426858\n",
      " 22.14963423 32.4290958  31.27850489 25.17230754 28.52396032 13.84983608\n",
      " 27.39951039 27.78139641 32.16130031 17.98773758 29.62934099 28.30626317\n",
      " 24.51201947 30.25106045 32.63566842 26.76914099 24.34369643 27.21308511\n",
      " 17.82457754 29.85706578 30.44662992 30.70220887  9.16740576 25.62343417\n",
      " 20.36132514 31.12440795 27.36123418 21.40441821 26.60349972 24.31174391\n",
      " 19.91997595 22.44294175 33.48205419 22.48024676 10.01718749 16.86302366\n",
      " 25.76205917 28.14676492  8.27189824 28.49473172 26.78836788 30.98605626\n",
      " 17.83713977 16.67296876 17.72150491 19.25727328 11.61117745 29.41810061\n",
      " 25.92221764 30.25205229 33.48762294 20.96873708 25.66831811 15.24760192\n",
      " 26.1072048  25.74832883 26.02406869 24.90565572 15.30762059 24.92890802\n",
      " 24.38402369 29.62627545 25.4065869  24.54976981 20.06811999 21.49674189\n",
      " 33.20373221 21.06311816 26.63785158 22.71536861  6.5719352  26.76818107\n",
      " 20.25290788 32.79308471 30.46997356 26.62667594 20.53181195 30.52815806\n",
      " 32.15391013 26.90896718 30.92370617 11.24939386 34.31563084 19.27428329\n",
      " 27.51933514 29.46516043 34.9531971  22.215815   11.31028276 16.56100025\n",
      " 28.86836967 25.72008606 27.48904213 26.08384309 23.792238   15.2424409\n",
      " 26.0216028  23.87602085 22.53942107 28.09901738 30.95577347 15.96559722\n",
      " 10.3039288  25.6095923  21.74844167 11.55070339 28.31112649 30.50070952\n",
      " 31.77545545 16.00287337 13.21019837  9.73494589 32.0068051  22.8012516\n",
      " 22.89192152 32.34776818 21.48963445 30.96876195 29.18066067 15.24486209\n",
      " 27.6332086  18.04931275 27.91077152 28.76971044 15.17762785 30.60538274\n",
      " 31.50858805 28.19881152 21.00946709 13.88239624 17.85498066 17.44234411\n",
      " 18.59640649 28.78744373 32.74607347 25.51134946 28.13694051 29.84456183\n",
      " 19.74054387 22.28785511 34.47421477 26.57329713 35.04072916 32.11209633\n",
      " 22.25988635 30.37644017 29.84793659 23.14716623 33.50977522 25.54042507\n",
      " 28.43026753 19.8596129  34.21068149 29.91962831 13.03868514 27.35379804\n",
      " 10.60795989 24.98966435 20.4813773  25.06934715  9.60625709 25.57143321\n",
      " 17.59655001 23.26238634 19.77727106 23.69860598 25.45020982 17.00510366\n",
      " 23.41007022 25.13777576 24.36435237 24.34004214 15.37464663 28.47841956\n",
      " 12.63156707 28.12645005 14.43072276 24.87141621 12.72699126 33.37974785\n",
      " 25.95455371 30.2238874  34.15920774 14.85057332 28.65174624 19.7099345\n",
      " 13.78778119 29.94003324 31.3485694   5.56040238]\n",
      "R squared score = 0.7527168636109156\n"
     ]
    }
   ],
   "source": [
    "y_pred09 = auto_model.predict(X_train09)\n",
    "print(y_pred09)\n",
    "print(f\"R squared score = {r2_score(y_pred09, y_train09)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the r squared score for the smaller test set. Is there an improvement in the test r squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yes, the smaller test r squared score is 0.64 and the new test score is 0.7527, there is a clear improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Backward Elimination \n",
    "\n",
    "The main way to produce a simpler linear regression model is to reduce the number of variables used in the model. In scikit-learn, we can do this by using recursive feature elimination. You can read more about RFE [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
    "\n",
    "In the next cell, we will import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the documentation and initialize an RFE model using the `auto_model` linear regression model. Set `n_features_to_select=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(auto_model,n_features_to_select=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and print the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 3 1 1]\n",
      "Index(['cylinders', 'displacement', 'horse_power', 'weight', 'acceleration',\n",
      "       'model_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X, y)\n",
    "print(selector.ranking_)\n",
    "print(auto.columns[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance is ranked from most important (1) to least important (4). Generate a model with the three most important features. The features correspond to variable names. For example, feature 1 is `cylinders` and feature 2 is `displacement`.\n",
    "\n",
    "Perform a test-train split on this reduced column data and call the split data `X_train_reduced`, `X_test_reduced`, `y_test_reduced`, `y_train_reduced`. Use an 80% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = auto[[\"cylinders\",\"acceleration\",\"model_year\"]]\n",
    "y_reduced = auto[\"mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new model called `auto_model_reduced` and fit this model. Then proceed to compute the r squared score for the model. Did this cause an improvement in the r squared score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model_reduced = LinearRegression()\n",
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(X_reduced, y_reduced, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.06161074 12.9570866  16.13188385 24.9642962  27.33658929 11.51056562\n",
      " 12.9746963  12.24263096 19.7191713  28.87115879 31.29275906 27.24854075\n",
      " 31.05678899 24.09135321 28.97329509 26.60452395 25.78441007 32.71110451\n",
      " 24.26745027 30.47616713 32.84493827 26.11807299 28.95920733 30.57478148\n",
      " 24.35105535 32.04595605 14.45643669 12.88664777 16.13188385 31.88042481\n",
      " 28.09989134 24.40740641 29.01908033 18.23743091 29.67366296 32.04243411\n",
      " 17.38209762 23.60138031 16.12483997 21.11286315 23.4649461  13.8476393\n",
      " 13.81241988 24.09135321 13.72437135 28.87820268 24.03852409 22.04920109\n",
      " 25.37544182 28.1602251  25.87153709 32.03186828 11.59861415 31.30684683\n",
      " 32.01425858 28.89229044 15.39981851 29.63492161 24.24984056 31.14835947\n",
      " 12.99230601 29.70183849 18.40204064 21.25374081 23.35928787 29.73353596\n",
      " 16.06144503 23.53538493 16.13892773 28.92398791 18.41965035 21.34178934\n",
      " 25.67875183 13.83002959 32.88367963 32.01824127 32.78506527 11.52817533\n",
      " 31.98256111 25.83723919 11.49295592 25.95958563 12.9746963  24.91146708\n",
      " 32.88367963 32.78506527 11.40490738 18.40908452 25.11834011 30.54660595\n",
      " 28.08626433 13.79481018 26.56930453 13.8476393  23.65068748 23.73521407\n",
      " 19.70156159 11.56339474 19.7191713  27.31897958 11.58100445 32.88367963\n",
      " 28.8288955  26.37559776 23.61899001 16.94495384 11.58100445 24.98190591\n",
      " 32.05652187 30.98987211 16.16710327 21.28896022 18.18460179 27.90664533\n",
      " 22.01750362 30.57478148 13.79481018 29.6771849  25.64353242 32.52796356\n",
      " 21.28896022 15.31176998 12.9746963  22.84466138 30.52195237 16.9836952\n",
      " 11.47534621 25.78441007 30.43038189 12.18980184 32.82380663 32.03186828\n",
      " 21.18330198 20.48645605 26.56930453 18.16699208 16.86394919 31.16244723\n",
      " 26.62213365 24.94668649 11.22881032 13.00991572 27.38941841 31.1941447\n",
      " 25.03473502 11.38729768 13.77720047 24.26745027 13.90046842 29.59970219\n",
      " 30.36346501 18.33160182 18.440782   24.91146708 24.94668649 19.75439071\n",
      " 32.93650875 28.20601034 28.90990015 24.09135321 21.28896022 32.00017081\n",
      " 11.4577365  24.35105535 24.99951561 29.74410179 16.84986143 19.84503968\n",
      " 17.38209762 11.54578504 21.18330198 32.8555041  23.25362963 31.31741265\n",
      " 26.58691424 27.91368921 16.97312937 13.00991572 32.76041168 30.50434266\n",
      " 26.07580969 32.87663575 11.35207826 13.77720047 13.02752542 26.56930453\n",
      " 24.5940693  23.54855119 28.07217657 22.01045974 31.18710082 18.47952335\n",
      " 28.09376897 23.4649461  28.91342209 32.82380663 25.78441007 24.26745027\n",
      " 31.2786713  32.15513623 25.74919066 23.65068748 14.52687552 24.85863796\n",
      " 31.22584218 11.52817533 12.24263096 17.69462889 26.53408512 13.02752542\n",
      " 23.56616089 12.24263096 13.72437135 25.01712532 14.4740464  26.60452395\n",
      " 26.76913368 27.3718087  15.32937969 27.30136987 15.32937969 17.61362424\n",
      " 21.89775761 24.0737435  20.48645605 27.90312339 11.52817533 24.71776031\n",
      " 22.79887614 32.79915304 32.83085051 32.77449945 23.72817019 30.16623629\n",
      " 32.10230711 16.89212472 31.3385443  18.48656723 28.08978628 31.89099063\n",
      " 26.44603659 18.16699208 31.24345188 27.28376017 20.46884635 30.51490848\n",
      " 31.2786713  31.06031093 23.35928787 13.04513513 32.08821934 13.74198106\n",
      " 32.73928004 22.09498633 25.03473502 29.66661908 31.92621004 32.86606992\n",
      " 12.26024067 29.71240432 31.296281   16.93438802 14.54448522 26.53408512\n",
      " 24.21462115 29.57152666 29.4975659  19.70156159 29.67014102 32.7533678\n",
      " 28.25531752 15.29416027 22.01750362 29.73001402 28.87866343 32.10935099\n",
      " 26.53408512 29.74762373 32.70406062 18.25504062 29.73001402 30.53251819\n",
      " 25.97719533 25.64353242 31.26810547 16.70546183 27.30136987 13.77720047\n",
      " 13.77720047 26.00537086 31.19062276 32.76041168 22.7530909  28.10739598\n",
      " 26.74800203 12.20741155 25.66114213 13.83002959 28.90637821 18.47247947\n",
      " 24.12657262 26.11807299 28.81832967 32.73928004 23.4473364  18.41612841\n",
      " 32.84141633 31.24697382 32.81676274 11.52817533 28.13909345 21.32417963\n",
      " 30.51138654]\n",
      "R squared score = 0.5970296390184493\n"
     ]
    }
   ],
   "source": [
    "auto_model_reduced.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred_reduced = auto_model_reduced.predict(X_train_reduced)\n",
    "print(y_pred_reduced)\n",
    "print(f\"R squared score = {r2_score(y_pred_reduced, y_train_reduced)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "You may obtain the impression from this lab that without knowing statistical methods in depth, it is difficult to make major progress in machine learning. That is correct. If you are motivated to become a data scientist, statistics is the subject you must be proficient in and there is no shortcut. \n",
    "\n",
    "Completing these labs is not likely to make you a data scientist. But you will have a good sense about what are there in machine learning and what are good for you. In your future career, you can choose one of the three tracks:\n",
    "\n",
    "* Data scientists who need to be proficient in statistical methods.\n",
    "\n",
    "* Data engineers who need to be good at programming.\n",
    "\n",
    "* Data integration specialists who are business or content experts but also understand data and programming. This cross-disciplinary track brings together data, technology, and business and will be in high demands in the next decade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
